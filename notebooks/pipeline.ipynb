{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and client import (Chat Completions API)\n",
    "# Minimal, with comments for clarity.\n",
    "\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os, ssl, certifi, httpx, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client config\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not set in environment\")\n",
    "\n",
    "CERTIFICATE_PATH = os.getenv(\"CERTIFICATE_PATH\")\n",
    "if not CERTIFICATE_PATH:\n",
    "    CERTIFICATE_PATH = certifi.where()\n",
    "    print(f\"CERTIFICATE_PATH not set in environment, using default: {CERTIFICATE_PATH}\", file=sys.stderr)\n",
    "\n",
    "# Set up OpenAI client with custom HTTP settings\n",
    "HTTP_TIMEOUT_SECS=30\n",
    "_ctx = ssl.create_default_context(cafile=CERTIFICATE_PATH)\n",
    "_http = httpx.Client(verify=_ctx, timeout=HTTP_TIMEOUT_SECS, follow_redirects=True)\n",
    "client = OpenAI(api_key=API_KEY, http_client=_http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de72504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and operational parameters\n",
    "MODEL_NAME = \"gpt-5-mini\"\n",
    "RATE_LIMIT_RPM = 20              # Per-minute cap\n",
    "MAX_RETRIES = 5                  # Exponential backoff tries\n",
    "BACKOFF_BASE_SECONDS = 2.0       # Initial backoff delay\n",
    "BACKOFF_CAP_SECONDS = 30.0       # Max backoff delay\n",
    "\n",
    "# Caching and artifacts\n",
    "FORCE_REGENERATE = True\n",
    "CACHE_PATH = Path(\"outputs/processed/task_b_simplified_cache.json\")\n",
    "ARTIFACTS_DIR = Path(\"outputs/raw/task_b_simplified\")\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read assumptions and questions CSVs with existence checks\n",
    "\n",
    "# Define input paths (relative to project root)\n",
    "QUESTIONS_CSV = Path(\"data/processed/questions.csv\")\n",
    "ASSUMPTIONS_CSV = Path(\"data/processed/assumptions.csv\")\n",
    "ECONOMIES_CSV = Path(\"data/processed/economies.csv\")\n",
    "\n",
    "# Check file existence early and fail fast with a clear message\n",
    "missing = [str(p) for p in (QUESTIONS_CSV, ASSUMPTIONS_CSV, ECONOMIES_CSV) if not p.exists()]\n",
    "if missing:\n",
    "    raise FileNotFoundError(\n",
    "        \"Missing required file(s): \" + \", \".join(missing)\n",
    "    )\n",
    "\n",
    "# Load DataFrames\n",
    "questions_df = pd.read_csv(QUESTIONS_CSV)\n",
    "assumptions_df = pd.read_csv(ASSUMPTIONS_CSV)\n",
    "economies_df = pd.read_csv(ECONOMIES_CSV)\n",
    "\n",
    "# Basic sanity check for directories\n",
    "Path(\"outputs/raw\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"outputs/processed\").mkdir(parents=True, exist_ok=True)\n",
    "print(\"Output directories ensured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f31b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumptions helper (pillar/section-specific with fallback to 'All')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_assumptions_map(df) -> Dict[str, Dict[str, List[str]]]:\n",
    "    mp: Dict[str, Dict[str, List[str]]] = defaultdict(lambda: defaultdict(list))\n",
    "    for _, r in df.iterrows():\n",
    "        p = str(r.get(\"pillar\", \"\")).strip()\n",
    "        s = str(r.get(\"section_name\", \"\")).strip()\n",
    "        a = str(r.get(\"assumptions\", \"\")).strip()\n",
    "        if p and s and a:\n",
    "            mp[p][s].append(a)\n",
    "    return mp\n",
    "\n",
    "assumptions_map = build_assumptions_map(assumptions_df)\n",
    "\n",
    "def applicable_assumptions(pillar: str, section: str) -> List[str]:\n",
    "    pillar = (pillar or \"\").strip()\n",
    "    section = (section or \"\").strip()\n",
    "    out: List[str] = []\n",
    "    out += assumptions_map.get(pillar, {}).get(section, [])\n",
    "    out += assumptions_map.get(pillar, {}).get(\"All\", [])\n",
    "    return [x for x in out if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: sanitize, cache, rate limit, retries, cache keys\n",
    "\n",
    "def sanitize_filename(name: str) -> str:\n",
    "    keep = [c if c.isalnum() or c in (\"-\", \"_\", \".\") else \"_\" for c in str(name)]\n",
    "    out = \"\".join(keep).strip(\"._\")\n",
    "    return out or \"untitled\"\n",
    "\n",
    "# Cache stored as a simple JSON dict\n",
    "\n",
    "def load_cache() -> Dict[str, Any]:\n",
    "    if CACHE_PATH.exists():\n",
    "        try:\n",
    "            return json.loads(CACHE_PATH.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "\n",
    "def save_cache(cache: Dict[str, Any]) -> None:\n",
    "    CACHE_PATH.write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# RPM rate limiter\n",
    "class RateLimiter:\n",
    "    def __init__(self, rpm: int):\n",
    "        self.rpm = max(1, int(rpm))\n",
    "        self._times: List[float] = []\n",
    "\n",
    "    def acquire(self):\n",
    "        now = time.time()\n",
    "        window = now - 60.0\n",
    "        self._times = [t for t in self._times if t >= window]\n",
    "        if len(self._times) >= self.rpm:\n",
    "            sleep_for = self._times[0] + 60.0 - now\n",
    "            if sleep_for > 0:\n",
    "                time.sleep(sleep_for)\n",
    "        self._times.append(time.time())\n",
    "\n",
    "rate_limiter = RateLimiter(RATE_LIMIT_RPM)\n",
    "\n",
    "\n",
    "def with_retries(fn):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                rate_limiter.acquire()\n",
    "                return fn(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                attempt += 1\n",
    "                if attempt > MAX_RETRIES:\n",
    "                    raise\n",
    "                # Exponential backoff with light jitter\n",
    "                delay = min(BACKOFF_CAP_SECONDS, BACKOFF_BASE_SECONDS * (2 ** (attempt - 1)))\n",
    "                # jitter via hashing current time\n",
    "                jitter = (hashlib.sha1(str(time.time()).encode()).digest()[0] / 255.0)\n",
    "                delay *= 0.8 + 0.4 * jitter\n",
    "                print(f\"Retry {attempt} after error: {e}. Sleeping ~{delay:.1f}s...\")\n",
    "                time.sleep(delay)\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "def cache_key_for(economy: str, row: Any) -> str:\n",
    "    payload = {\n",
    "        \"economy\": str(economy),\n",
    "        \"pillar\": str(row.get(\"pillar\", \"\")),\n",
    "        \"section_name\": str(row.get(\"section_name\", \"\")),\n",
    "        \"question_number\": str(row.get(\"question_number\", \"\")),\n",
    "        \"question_text\": str(row.get(\"question_text\", \"\")),\n",
    "        \"response_type\": str(row.get(\"response_type\", \"\")),\n",
    "    }\n",
    "    return hashlib.sha1(json.dumps(payload, sort_keys=True).encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "print(\"Utilities initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ed4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Responses API helper\n",
    "@with_retries\n",
    "def call_responses_api(instructions: str, input_text: str):\n",
    "    \"\"\"\n",
    "    Minimal wrapper for Responses API.\n",
    "    Returns the response object.\n",
    "    \"\"\"\n",
    "    return client.responses.create(\n",
    "        model=MODEL_NAME,\n",
    "        instructions=instructions,\n",
    "        input=input_text,\n",
    "        tools=[{\"type\": \"web_search_preview\",\n",
    "                \"search_context_size\": \"low\"\n",
    "        }],\n",
    "        reasoning={\n",
    "        \"effort\": \"low\"\n",
    "        },\n",
    "        store=True,\n",
    "        timeout=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27e4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_instructions_and_input(economy: str, row: Any, extra_assumptions: List[str]) -> (str, str):\n",
    "    \"\"\"\n",
    "    Compose instructions and input for the Responses API.\n",
    "    \"\"\"\n",
    "    pillar = str(row.get(\"pillar\", \"\")).strip()\n",
    "    section = str(row.get(\"section_name\", \"\")).strip()\n",
    "    qnum = str(row.get(\"question_number\", \"\")).strip()\n",
    "    qtext = str(row.get(\"question_text\", \"\")).strip()\n",
    "    hint = str(row.get(\"hint\", \"\")).strip()\n",
    "    rtype = str(row.get(\"response_type\", \"\")).strip().lower()\n",
    "\n",
    "    assumptions_text = \"\\n\".join([f\"- {a}\" for a in extra_assumptions]) if extra_assumptions else \"- None\"\n",
    "\n",
    "    if rtype == \"integer\":\n",
    "        format_spec = (\n",
    "            \"Return ONLY a JSON object with keys: \"\n",
    "            \"value (integer), reasoning (string, <= 40 words), confidence (float, 0-1, 1 decimal), \"\n",
    "            \"sources (array up to 2 items with fields: title, url)\"\n",
    "        )\n",
    "    else:\n",
    "        format_spec = (\n",
    "            \"Return ONLY a JSON object with keys: \"\n",
    "            \"answer (one of: 'Yes', 'No', 'Don't know'), reasoning (string, <= 40 words), confidence (float, 0-1, 1 decimal), \"\n",
    "            \"sources (array up to 2 items with fields: title, url)\"\n",
    "        )\n",
    "\n",
    "    instructions = (\n",
    "        \"You are a careful assistant. Answer concisely and factually; prefer official legal sources when known. \"\n",
    "        \"If unsure, answer 'Don't know'. Output STRICT JSON only; no prose, no markdown. \"\n",
    "        \"Include up to 2 authoritative legal sources with live URLs (e.g., official gazettes, government or parliament sites). \"\n",
    "        \"If no authoritative source is known, return an empty sources array.\\n\"\n",
    "        \"Rate confidence 0–1 (1 decimal). High score only if the answer is supported by well-established facts or strong reasoning. \"\n",
    "        \"Use low confidence if: ambiguous, lack of data, conflicting interpretations, or you are guessing.\"\n",
    "    )\n",
    "\n",
    "    input_parts = [\n",
    "        f\"Economy: {economy}\",\n",
    "        f\"Pillar: {pillar}\",\n",
    "        f\"Section: {section}\",\n",
    "        f\"Question {qnum}: {qtext}\",\n",
    "        f\"Response type: {rtype}\",\n",
    "    ]\n",
    "    if hint:\n",
    "        input_parts.append(f\"Hint: {hint}\")\n",
    "    input_parts.append(\"Assumptions:\\n\" + assumptions_text)\n",
    "    input_parts.append(\"\\nFORMAT:\\n\" + format_spec)\n",
    "\n",
    "    input_text = \"\\n\".join(input_parts)\n",
    "    return instructions, input_text\n",
    "\n",
    "print(\"Responses API helpers ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bffc0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver using Responses API\n",
    "import uuid\n",
    "from datetime import timezone\n",
    "\n",
    "cache = load_cache()\n",
    "\n",
    "econ_col = \"economy_name\"\n",
    "if econ_col not in economies_df.columns:\n",
    "    raise KeyError(f\"Expected column '{econ_col}' in economies.csv; found: {list(economies_df.columns)}\")\n",
    "\n",
    "economies = [str(x) for x in economies_df[econ_col].dropna().astype(str).unique()]\n",
    "\n",
    "for econ in economies:\n",
    "    for idx, row in questions_df.head(1).iterrows():\n",
    "        pillar = str(row.get(\"pillar\", \"\")).strip()\n",
    "        section = str(row.get(\"section_name\", \"\")).strip()\n",
    "        qnum = str(row.get(\"question_number\", \"\")).strip()\n",
    "        rtype = str(row.get(\"response_type\", \"\")).strip().lower()\n",
    "\n",
    "        key = cache_key_for(econ, row)\n",
    "\n",
    "        if (not FORCE_REGENERATE) and key in cache:\n",
    "            cached = cache[key]\n",
    "            content = cached.get(\"content\", \"\")\n",
    "            structured = cached.get(\"structured\")\n",
    "            usage_total_tokens = cached.get(\"usage_total_tokens\")\n",
    "        else:\n",
    "            extra_assumps = applicable_assumptions(pillar, section)\n",
    "            instructions, input_text = build_instructions_and_input(econ, row, extra_assumps)\n",
    "\n",
    "            resp = call_responses_api(instructions, input_text)\n",
    "\n",
    "            # Extract output text (Responses API)\n",
    "            try:\n",
    "                content = resp.output_text.strip()\n",
    "            except Exception:\n",
    "                content = \"\"\n",
    "\n",
    "            # Parse JSON content if possible\n",
    "            structured = None\n",
    "            try:\n",
    "                structured = json.loads(content)\n",
    "            except Exception:\n",
    "                structured = None\n",
    "\n",
    "            # Usage metric (if available)\n",
    "            usage_total_tokens = getattr(resp, \"usage\", None)\n",
    "            # --- Fix: convert to int if possible ---\n",
    "            if usage_total_tokens is not None:\n",
    "                if isinstance(usage_total_tokens, dict):\n",
    "                    usage_total_tokens = usage_total_tokens.get(\"total_tokens\")\n",
    "                elif hasattr(usage_total_tokens, \"total_tokens\"):\n",
    "                    usage_total_tokens = usage_total_tokens.total_tokens\n",
    "                else:\n",
    "                    usage_total_tokens = int(usage_total_tokens) if isinstance(usage_total_tokens, (int, float, str)) else None\n",
    "\n",
    "            cache[key] = {\n",
    "                \"economy\": econ,\n",
    "                \"pillar\": pillar,\n",
    "                \"section_name\": section,\n",
    "                \"question_number\": qnum,\n",
    "                \"response_type\": rtype,\n",
    "                \"content\": content,\n",
    "                \"structured\": structured,\n",
    "                \"usage_total_tokens\": usage_total_tokens  # Now always serializable\n",
    "            }\n",
    "            save_cache(cache)\n",
    "\n",
    "        out_dir = ARTIFACTS_DIR / sanitize_filename(econ) / sanitize_filename(pillar) / sanitize_filename(section)\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "        out_path = out_dir / f\"{sanitize_filename(qnum)}.json\"\n",
    "\n",
    "        sources = None\n",
    "        reasoning = None\n",
    "        answer_or_value = None\n",
    "        confidence = None\n",
    "        try:\n",
    "            if isinstance(structured, dict):\n",
    "                sources = structured.get(\"sources\")\n",
    "                reasoning = structured.get(\"reasoning\")\n",
    "                confidence = structured.get(\"confidence\")\n",
    "                if rtype == \"integer\":\n",
    "                    answer_or_value = structured.get(\"value\")\n",
    "                else:\n",
    "                    answer_or_value = structured.get(\"answer\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        artifact = {\n",
    "            \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "            \"economy\": econ,\n",
    "            \"question\": {\n",
    "                \"pillar\": str(row.get(\"pillar\", \"\")),\n",
    "                \"section_name\": str(row.get(\"section_name\", \"\")),\n",
    "                \"question_number\": str(row.get(\"question_number\", \"\")),\n",
    "                \"question_text\": str(row.get(\"question_text\", \"\")),\n",
    "                \"response_type\": rtype,\n",
    "                \"hint\": str(row.get(\"hint\", \"\")),\n",
    "            },\n",
    "            \"assumptions_used\": applicable_assumptions(pillar, section),\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"usage\": {\"total_tokens\": usage_total_tokens},\n",
    "            \"output\": {\n",
    "                \"raw\": content,\n",
    "                \"structured\": structured,\n",
    "                \"reasoning\": reasoning,\n",
    "                \"sources\": sources,\n",
    "                \"confidence\": confidence,\n",
    "                \"answer\": answer_or_value if rtype != \"integer\" else None,\n",
    "                \"value\": answer_or_value if rtype == \"integer\" else None,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        out_path.write_text(json.dumps(artifact, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        print(f\"   ✅ Done {idx + 1}/{len(questions_df)}\")\n",
    "\n",
    "print(\"Done. Artifacts written under 'outputs/raw/task_b_simplified/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
